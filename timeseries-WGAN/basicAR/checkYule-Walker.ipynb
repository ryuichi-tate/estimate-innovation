{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## そもそもARモデルをしっかり学習できるのかを確かめる"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次時刻予測をさせる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "path = os.getcwd()\n",
    "path=path[:path.find('timeseries-WGAN')+15]\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import math\n",
    "import sys\n",
    "sys.path.append(path+\"/\")\n",
    "import random\n",
    "import statsmodels.api as sm\n",
    "from scipy.stats import norm\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 人工データを生成してくれる機械が置いてあるところ\n",
    "import tsModel\n",
    "# 学習用のニューラルネットが置いてあるところ\n",
    "import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# フォルダを作成（既にあるならそれで良し）\n",
    "os.makedirs(\"output-images\", exist_ok=True)\n",
    "os.makedirs(\"parameters\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "p=7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NNで確かめる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = models.LinearPredictNet(p = p, input_dim=1, is_bias=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'change_seed/parameters/network_epoch20000_batchSize64_networkSeed0_p7_networkBiasTrue_dataSeed0.pth'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameter_path = \"change_seed/parameters/network_epoch20000_batchSize64_networkSeed0_p7_networkBiasTrue_dataSeed{0}.pth\".format(i)\n",
    "parameter_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.load_state_dict(torch.load(parameter_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('fc1.weight',\n",
       "              tensor([[ 0.3131, -0.3650,  0.2718, -0.4386,  0.3368, -0.4201,  0.2601, -0.0106]])),\n",
       "             ('fc1.bias', tensor([0.0559]))])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.3131, -0.3650,  0.2718, -0.4386,  0.3368, -0.4201,  0.2601, -0.0106])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.state_dict()[\"fc1.weight\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.055861249566078186"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.state_dict()[\"fc1.bias\"].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = []\n",
    "mu = []\n",
    "\n",
    "for i in range(10):\n",
    "    net = models.LinearPredictNet(p = p, input_dim=1, is_bias=True)\n",
    "    parameter_path = \"change_seed/parameters/network_epoch20000_batchSize64_networkSeed0_p7_networkBiasTrue_dataSeed{0}.pth\".format(i)\n",
    "    net.load_state_dict(torch.load(parameter_path))\n",
    "    params.append(np.array(net.state_dict()[\"fc1.weight\"][0]))\n",
    "    mu.append(net.state_dict()[\"fc1.bias\"].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 0.31314477, -0.36504686,  0.27184433, -0.43856618,  0.33677167,\n",
       "        -0.42010248,  0.26005104, -0.01064355], dtype=float32),\n",
       " array([ 0.29983357, -0.3969987 ,  0.27157873, -0.38687065,  0.2769836 ,\n",
       "        -0.3992239 ,  0.2647001 ,  0.01933478], dtype=float32),\n",
       " array([ 0.27080438, -0.39342478,  0.28358912, -0.40527612,  0.22151943,\n",
       "        -0.41049236,  0.2654277 ,  0.0069396 ], dtype=float32),\n",
       " array([ 0.29360873, -0.44982007,  0.2733666 , -0.43622828,  0.27736217,\n",
       "        -0.42202893,  0.27404442, -0.00865356], dtype=float32),\n",
       " array([ 0.2563577 , -0.38253444,  0.32640874, -0.47440857,  0.26235667,\n",
       "        -0.3748935 ,  0.30355993, -0.00252023], dtype=float32),\n",
       " array([ 0.32526284, -0.35008043,  0.2832891 , -0.35309443,  0.29167408,\n",
       "        -0.37545577,  0.29418257, -0.01228052], dtype=float32),\n",
       " array([ 0.23107277, -0.40981576,  0.25780845, -0.38802522,  0.26731107,\n",
       "        -0.37267247,  0.26718327,  0.00619552], dtype=float32),\n",
       " array([ 0.32252413, -0.40755153,  0.30345628, -0.36727062,  0.2839524 ,\n",
       "        -0.4082837 ,  0.33507344, -0.00471937], dtype=float32),\n",
       " array([ 0.2831305 , -0.405863  ,  0.27545816, -0.42338973,  0.2905702 ,\n",
       "        -0.38879618,  0.28092146,  0.01691499], dtype=float32),\n",
       " array([ 0.29322898, -0.37868756,  0.2658059 , -0.38401416,  0.27546477,\n",
       "        -0.37118652,  0.33535787,  0.00455801], dtype=float32)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.055861249566078186,\n",
       " 0.0794120505452156,\n",
       " -0.09066326916217804,\n",
       " -0.09570492804050446,\n",
       " 0.016815723851323128,\n",
       " 0.0342823751270771,\n",
       " 0.022684520110487938,\n",
       " 0.02085406892001629,\n",
       " 0.07357200980186462,\n",
       " -0.03404462710022926]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.28889686 -0.39398235  0.28126055 -0.40571442  0.2783966  -0.3943136\n",
      "  0.28805017  0.00151257]\n",
      "[0.02822203 0.02613973 0.01899416 0.03525268 0.02718427 0.01918498\n",
      " 0.02692717 0.01054511]\n"
     ]
    }
   ],
   "source": [
    "print(np.array(params).mean(axis = 0))\n",
    "print(np.array(params).std(axis = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.008306917361915111\n",
      "0.05924134751805972\n"
     ]
    }
   ],
   "source": [
    "print(np.array(mu).mean())\n",
    "print(np.array(mu).std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 最小二乗法で確かめる 最尤推定と同じ？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ar_data = np.array(trainData.view(-1))\n",
    "ar_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sm.tsa.AR(ar_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.select_order(maxlag=10, ic='aic'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.fit(maxlag=p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result.sigma2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data = tsModel.SARIMA(a=[0.3,-0.4,0.3,-0.4,0.3,-0.4,0.3], N=1400, random_seed=0, sigma=2)\n",
    "Data = torch.tensor(Data, dtype=torch.float)\n",
    "Data = torch.tensor(Data)\n",
    "Data=Data.view(1,-1)\n",
    "trainData = Data[:,:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ar_data = np.array(trainData.view(-1))\n",
    "model = sm.tsa.AR(ar_data)\n",
    "result = model.fit(maxlag=p)\n",
    "print(result.params)\n",
    "print(result.sigma2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = []\n",
    "sigma2 = []\n",
    "for i in range(10):\n",
    "    Data = tsModel.SARIMA(a=[0.3,-0.4,0.3,-0.4,0.3,-0.4,0.3], N=1400, random_seed=i, sigma=2)\n",
    "    Data = torch.tensor(Data, dtype=torch.float)\n",
    "    Data = torch.tensor(Data)\n",
    "    Data=Data.view(1,-1)\n",
    "    trainData = Data[:,:1000]\n",
    "\n",
    "    ar_data = np.array(trainData.view(-1))\n",
    "    model = sm.tsa.AR(ar_data)\n",
    "    result = model.fit(maxlag=p)\n",
    "    params.append(result.params)\n",
    "    sigma2.append(result.sigma2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(params).mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(params).std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(sigma2).mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(sigma2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(sigma2).std()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
